%!TEX ROOT=geometria1.tex

\section{Spazio vettoriale}%
\label{sec:spazio_vettoriale}

\begin{Def}{Spazio vettoriale}
  Un insieme $V$ si definisce spazio vettoriale sul campo $\mathbb{K}$ se sono definite
  su $V$ due operazioni
  \begin{enumerate}
    \item \textbf{Somma} definita come
      \begin{align*}
        +:\,&V\times V\to V\\
            &(\vec{x},\vec{y})\mapsto\vec{x}+\vec{y}
      \end{align*}
      rispetto alla quale $(V,\,+)$ ha la struttura di gruppo commutativo. Ovvero
      \begin{enumerate}
        \item $\vec{x}+\vec{y} = \vec{y}+\vec{x}$
        \item $(\vec{x}+\vec{y})+\vec{z} = \vec{x} + (\vec{y}+\vec{z})$
        \item $\exists\vec{o}\in V\suchthat \vec{x}+\vec{o}=\vec{x}$ e si definisce
          $\vec{o}$ vettore nullo.
        \item $\forall\vec{x}\in V\,\exists\vec{x}\in
          V\suchthat\vec{x}+(-\vec{x})=\vec{o}$ e si definisce opposto.
      \end{enumerate}
    \item \textbf{Prodotto} definito per uno scalare
      \begin{align*}
        &\mathbb{K}\times V\to V\\
        &(\lambda,\vec{x})\mapsto \lambda\vec{x}
      \end{align*}
      e si ha che
      \begin{enumerate}
        \item $\lambda(\vec{x}+\vec{y}) = \lambda\vec{x}+\lambda\vec{y}$
        \item $(\lambda+\mu)\vec{x} = \lambda\vec{x}+\mu\vec{x}$
        \item $(\lambda\mu)\vec{x} = \lambda(\mu\vec{x})$
        \item $1\vec{x} = \vec{x}$
      \end{enumerate}
  \end{enumerate}
\end{Def}

\begin{Def}{Eleementi dello spazio}
  Gli elementi di $V$ sono detti vettori, quelli di $\mathbb{K}$ scalari.
\end{Def}

\begin{Def}{Campo}
  Un campo è un insieme i cui elementi sono detti numeri, che contiene $0$ e $1$ e ha
  due operazioni $+$ e $\cdot$ che verificano
  \begin{multicols}{2}
    \begin{enumerate}
      \item $\alpha+\beta = \beta+\alpha$
      \item $\alpha+(\beta+\gamma) = (\alpha+\beta)+\gamma$
      \item $\alpha+0 = \alpha$
      \item $\alpha+(-\alpha)=0$
      \columnbreak%
      \item $\alpha\beta = \beta\alpha$
      \item $(\alpha\beta)\gamma = \alpha(\beta\gamma)$
      \item $1\alpha = \alpha$
      \item $\alpha\alpha^{-1}=1$ se $\alpha\neq0$
      \item $(\alpha+\beta)\gamma = \alpha\gamma+\beta\gamma$
    \end{enumerate}
  \end{multicols}
\end{Def}

\subsection{Spazi particolari}%
\label{sub:spazi_particolari}

In generale $\mathbb{R}^n$ è uno spazio vettoriale, così come anche in generale
$\mathbb{K}^n$. Infatti si ha che
\begin{equation*}
  (x_1,\ldots,x_2)+(y_1,\ldots,y_n) = (x_1+y_1,\ldots,x_n+y_n)
\end{equation*}
e
\begin{equation*}
  \lambda(x_1,\ldots,x_n) = (\lambda x_1,\ldots,\lambda x_n)
\end{equation*}
In generale anche $\mathbb{K}^{m,n}$ è uno spazio vettoriale (e quindi anche
$\mathbb{R}^{m,n}$).\\
Il più piccolo spazio vettoriale è quello composto dal solo vettore nullo, ovvero
$\{\vec{o}\}$.\
Un caso particolare è lo spazio dei polinomi reali in $x$, denotato come $\mathbb{R}[x]$
che è
\begin{equation*}
  \mathbb{R}[x]\bydef \left\{ a_0+a_1x+\cdots+a_n x^n\Setsuchthat
  n\in\mathbb{N},\,a_i\in\mathbb{R},\,i=0,\ldots,n \right\}
\end{equation*}
È anche interessante il caso in cui si consideri l'insieme
\begin{equation*}
  \mathscr{F} = \left\{ f:\,\mathbb{R}\to\mathbb{R}\qq{funzione} \right\}
\end{equation*}
in quanto anche questo è uno spazio vettoriale infatti
\begin{equation*}
  (f+g)(x)\bydef f(x)+g(x)
\end{equation*}
e
\begin{equation*}
  (\lambda f)(x)\bydef \lambda f(x)
\end{equation*}

\subsection{Proprietà formali}%
\label{sub:proprieta_formali}

In un campo vettoriale su $\mathbb{K}$ valgono le seguenti proprietà
\begin{enumerate}
  \item Vettore nullo unico
    \begin{proof}
      Supponiamo per assurdo che esistano $\vec{o}$ e $\vec{o'}$ nulli in modo che
      $\vec{o}\neq\vec{o'}$. Allora si ha $\vec{o}=\vec{o}+\vec{o'}$ sfruttando il fatto
      che $\vec{o'}$ è un vettore nullo. Analogamente si ha che
      $\vec{o'}=\vec{o'}+\vec{o}$. Da queste due relazioni si deduce che
      $\vec{o'}=\vec{o}$ che va contro l'ipotesi iniziale.
    \end{proof}
  \item Opposto unico
    \begin{proof}
      Supponiamo per assurdo che esistano $\vec{x_1}\neq\vec{x_2}$ oposti di $\vec{x}$.
      Allora possiamo scrivere $(\vec{x}+\vec{x_1})+\vec{x_2} =
      \vec{o}+\vec{x_2}=\vec{x_2}$. Analogamente si ha che
      $(\vec{x}+\vec{x_1})+\vec{x_2}=\vec{x}+(\vec{x_2}+\vec{x_1})=(\vec{x}+\vec{x_2})
      +\vec{x_1}=\vec{o}+\vec{x_1}=\vec{x_1}$. Si deduce quindi che
      $\vec{x_1}=\vec{x_2}$ ma per ipotesi questo non può essere.
    \end{proof}
  \item Se per $\vec{x}$, $\vec{y}$, $\vec{z}$ si ha $\vec{x}+\vec{y}=\vec{x}+\vec{z}$
    allora $\vec{y}=\vec{z}$
    \begin{proof}
      La dimostrazione segue direttamente dalla seconda proprietà, infatti si può
      aggiungere $-\vec{x}$ ad entrambi i membri e ottenere
      $\vec{x}+\vec{y}-\vec{x}=\vec{x}+\vec{z}-\vec{x}$. Si ottiene
      $\vec{o}+\vec{y}=\vec{z}+\vec{o}$ e infine $\vec{y}=\vec{z}$.
    \end{proof}
  \item Solo su $\mathbb{R}$ vale che $\lambda\vec{x}=\vec{o}$ con
    $\lambda\in\mathbb{R}$ allora $\lambda=0\lor\vec{x}=\vec{o}$
    \begin{proof}
      Essendo una biimplicazione, bisogna dimostrare entrambi i versi. Dimostriamo
      $\Leftarrow$. Possiamo provare che $0\vec{x}\vec{o}$ e $\lambda\vec{o}=\vec{o}$.
      Per il primo caso si può dire che $0\vec{x}=(0+0)\vec{x}=0\vec{x}+0\vec{x}$. Per
      il punto precedente, abbiamo che $o\vec{x}=o\vec{x}+o\vec{x}$ e semplificando si
      ottiene $\vec{o}=o\vec{x}$. Il secondo caso si dimostra analogamente
      $\lambda\vec{o}=\lambda(\vec{o}+\vec{o})=\lambda\vec{o}+\lambda\vec{o}$. Per il
      punto precedente $\lambda\vec{o}=\vec{o}\lambda+\lambda\vec{o}$, semplificando
      $\vec{0}=\lambda\vec{o}$.\\
      L'altro vers ($\Rightarrow$) dice che $\lambda\vec{x}=\vec{o}$. Se $\lambda=0$ è
      immediato. Se $\lambda\neq0$, sicuramente $\exists\lambda^{-1}$. Possiamo allora
      scrivere $\vec{o}=\lambda^{-1}\vec{o}=\lambda^{-1}(\lambda\vec{o}\vec{x})=
      (\lambda^{-1}\lambda)\vec{x}=\vec{x}$.
    \end{proof}
  \item $(-1)\vec{x} = -\vec{x}$
    \begin{proof}
      Si ha che $\vec{x}+(-1)\vec{x}=1\vec{x}+(-1)\vec{x}=(1-1)\vec{x}=\vec{o}$.
    \end{proof}
\end{enumerate}

\subsection{Sottoinsiemi di spazi vettoriali}%
\label{sub:sottoinsiemi_di_spazi_vettoriali}

\begin{Def}{Sottospazio vettoriale}
  Sia $V$ uno spazio vettoriale su $\mathbb{K}$. Un sottoinsieme $W$ di $V$ è un
  sottospazio vettoriale di $V$ se $W$ è uno spazio vettoriale rispetto alle stesse
  operazioni di $V$, ovvero rispetto alla somma e al prodotto per scalari. Formalmente
  se vale
  \begin{equation*}
    \forall\lambda,\mu\in\mathbb{K}\;\forall\vec{x},\vec{y}\in W\quad
    \lambda\vec{x}+\mu\vec{y}\in W
  \end{equation*}
\end{Def}
Si noti che $(W,+)$ è un sottgruppo di $V$ rispetto alla somma. Si noti anche che il
vettore nullo di $V$ appartiene ad ogni sottospazio vettoriale $W$ di $V$, infatti
$\lambda\vec{x}\in W\quad\lambda=0\implies\lambda\vec{x}=\vec{o}\in W$.

\begin{SubDef}{Sottospazi impropri}
  Ogni spazio vettoriale ha almeno due sottospazi vettoriali: se stesso e $\{\vec{o}\}$.
\end{SubDef}

Si noti anche che se $W$ è un sottospazio vettoriale, $\vec{x}\in W\implies-\vec{x}\in
W$.

\subsubsection{Esempio fondamentale di sottospazio vettoriale}%
\label{ssub:esempio_fondamentale_di_sottospazio_vettoriale}

Si prenda l'insieme delle soluzioni di un sistema lineare omogeneo di $m$ equazioni in
$n$ incognite. L'insieme è un sottospazio vettoriale di $\mathbb{R}^n$. In generale
l'insieme di soluzioni di $AX=B$ è un sottospazio vettoriale di $\mathbb{R}^n$ se e solo
se il sistema è omogeneo.

\begin{Def}{Nullspace}
  Sia $AX=O$ un sistema lineare omogeneo con $A\in\mathbb{R}^{m,n}$ e
  $X=
  \begin{pmatrix}
    X_1\\\vdots\\X_n
  \end{pmatrix}\in\mathbb{R}^{n,1}$. Allora
  \begin{equation*}
    N(A)\bydef \left\{ X\in\mathbb{R}^{n,1}\Setsuchthat AX = O
    \right\}\subseteq\mathbb{R}^n
  \end{equation*}
  si definisce \textbf{nullspace} di $A$ che contiene l'insieme delle soluzioni.
\end{Def}

Il nullspace è uno sottospazio vettoriale in quanto
$\forall\lambda,\mu\in\mathbb{R}\;\forall X,Y\in N(A)\quad \lambda X+\mu Y\in N(A)$.
Infatti si ha che $A(\lambda X+\mu Y) = O = \lambda AX+\mu (AY)$ in quanto sia $X$ che
$Y$ sono soluzioni.

\subsubsection{Esempi di sottospazi vettoriali nello spazio delle matrici}%
\label{sub:esempi_di_sottospazi_vettoriali_nello_spazio_dell_matrici}

\begin{Def}{Insieme delle matrici diagonali}
  \begin{equation*}
    \mathscr{D}\left( \mathbb{R}^{n,n} \right) \bydef \left\{ D =
      \begin{pmatrix}
        d_1 & \cdots & 0\\
        0 & \ddots & \vdots\\
        0 & 0 & d_n
      \end{pmatrix}\in\mathbb{R}^{n,n}
      \Setsuchthat d_i\in\mathbb{R}^{n,n}
    \right\}
  \end{equation*}
  È uno sottospazio vettoriale in quanto combinazioni lineari di matrici diagonali, sono
  ancora matrici diagonali.
\end{Def}

\begin{Def}{Insieme delle matrici triangolari superiori e inferiori}
    \begin{equation*}
      \tau \left( \mathbb{R}^{n,n} \right)\bydef \left\{
        \begin{pmatrix}
          a_{11} & \cdots & \cdots & a_{1n}\\
          0 & a_{22} & \cdots & a_{2n}\\
          \vdots & \cdots & \ddots & \vdots\\
          0 & \cdots & 0 & a_{nn}
        \end{pmatrix}\in\mathbb{R}^{n,n}
        \Setsuchthat a_{ij}\in\mathbb{R}
      \right\}
    \end{equation*}
    e
    \begin{equation*}
      \tau \left( \mathbb{R}^{n,n} \right)\bydef \left\{
        \begin{pmatrix}
          a_{11} & 0 & \cdots & 0\\
          \vdots & a_{22} & 0 & \vdots\\
          \vdots & \cdots & \ddots & \vdots\\
          a_{n1} & \cdots & \cdots & a_{nn}
        \end{pmatrix}\in\mathbb{R}^{n,n}
        \Setsuchthat a_{ij}\in\mathbb{R}
      \right\}
    \end{equation*}
    sono sottospazi vettoriali di $\mathbb{R}^{n,n}$.
\end{Def}

\begin{Def}{Insieme delle matrici simmetriche}
  \begin{equation*}
    \mathscr{S}\left( \mathbb{R}^{n,n} \right)\bydef \left\{A\in\mathbb{R}^{n,n}\Setsuchthat
    \transp A = A\right\}
  \end{equation*}
  è uno sottospazio vettoriale di $\mathbb{R}^{n,n}$.
\end{Def}

\begin{Def}{Insieme delle matrici antisimmetriche}
  \begin{equation*}
    \mathscr{A}\left( \mathbb{R}^{n,n} \right)\bydef \left\{A\in\mathbb{R}^{n,n}\Setsuchthat
    \transp A = -A\right\}
  \end{equation*}
  è un sottospazio vettoriale di $\mathbb{R}^{n,n}$.
\end{Def}

\begin{Def}{Insieme delle matrici ortogonali reali}
  \begin{equation*}
    \mathscr{O}(n,\mathbb{R})\bydef \left\{ A\in\mathbb{R}^{n,n}\Setsuchthat A\transp A
    = I = \transp A A\right\}
  \end{equation*}
  \textbf{non} è uno sottospazio vettoriale di $\mathbb{R}^{n,n}$ in quanto $O\notin
  O(n,\mathbb{R})$.
\end{Def}

\subsection{Combinazioni lineari}%
\label{sub:combinazioni_lineari}

\begin{Def}{Combinazione lineare}
  Dati $l$ vettori $\vec{v_1},\ldots,\vec{v_l}$ di uno spazio vettoriale $V$ su
  $\mathbb{K}$, si dice che un vettore $\vec{x}$ è una combinazione lineare dei vettori
  $\vec{v_1},\ldots,\vec{v_l}$ se esistono $x_1,\ldots,x_l\in\mathbb{K}$ tali che
  $\vec{x}=x_1\vec{v_1}+\cdots+x_l\vec{v_l}$. $x_i$ si dice coefficiente.
\end{Def}

\begin{Def}{Insieme delle combinazioni lineari}
  Fissando i vettori $\vec{v_1},\ldots,\vec{v_2}$, si definisce
  \begin{equation*}
    \mathscr{L}(\vec{v_1},\ldots,\vec{v_l})\bydef \left\{
    x_1\vec{v_1}+\cdots+x_l\vec{v_l} \Setsuchthat x_i\in\mathbb{K},\;i=1,\ldots,l \right\}
  \end{equation*}
\end{Def}

\begin{Def}{Sistema di generatori di $\mathscr{L}(\vec{v_1},\ldots,\vec{v_l})$}
  Il sistema di generatori è l'insieme $\{x_1\vec{v_1},\ldots,x_l\vec{v_l}\}$.
\end{Def}

\begin{Thm}{Sottospazio delle combinazioni lineari}
  $\mathscr{L}(\vec{v_1},\ldots,\vec{v_l})$ è un sottospazio vettoriale di $V$ ed è il
  più piccolo sottospazio vettoriale di $V$ a contenere i vettori
  $\vec{v_1},\ldots,\vec{v_l}$.
\end{Thm}

\begin{Def}{Sistema di generatori di un sottospazio}
  Siano $\vec{v_1},\ldots,\vec{v_l}$ vettori di $V$. Si dice che un sottospazio
  vettoriale $W$ di $V$ ha come sistema di generatori $\{\vec{v_1},\ldots,\vec{v_l}\}$
  se $W=\mathscr{L}(\vec{v_1},\ldots,\vec{v_l})$.
\end{Def}

\begin{Thm}{Modifiche ai generatori}
  Detto $W=\mathscr{L}(\vec{v_1},\ldots,\vec{v_l})$, si possono aggiungere o sostituire
  più generatori di $W$ con loro combinazioni lineari.
\end{Thm}

Come conseguenza di questo teorema si ha che $W=\mathscr{L}(\vec{v_1},\ldots,\vec{v_l})$
ha infiniti sistemi generatori.

\begin{Def}{Spazi finitiamente generati}
  Uno spazio vettoriale $V$ si dice finitamente generato se esistono $l$ vettori
  $\vec{v_1},\ldots,\vec{v_l}$ di $V$ tali che $V=\mathscr{L}(\vec{v_1},\ldots,\vec{v_l}
  )$.
\end{Def}

\begin{Def}{Sottospazi finitiamente generati}
  Un sottospazio vettoriale $W$ si dice finitamente generato se esistono $l$ vettori
  $\vec{v_1},\ldots,\vec{v_l}$ di $W$ tali che $W=\mathscr{L}(\vec{v_1},\ldots,\vec{v_l}
  )$.
\end{Def}

\subsubsection{Esempi di spazi finitamente generati}%
\label{ssub:esempi_di_spazi_finitamente_generati}

$\mathbb{R}^n$ è finitamente generato, in quanto possiamo definire
$\vec{e_1}=(1,0,\ldots,0)$, $\vec{e_i}=(0,\ldots,1,\ldots,0)$ dove l'$1$ è all'$i$-esimo
posto e $\vec{e_n}=(0,\ldots,1)$. In questo modo una qualsiasi $n$-upla la si può
scrivere come $(x_1,\ldots,x_n)=x_1\vec{e_1}+\cdots+x_n\vec{e_n}$.\\
Analogamente anche $\mathbb{R}^{m,n}$ è finitamente generato, creando delle matrici
nello stesso modo.

\subsubsection{Dipendenza lineare}%
\label{sub:dipendenza_lineare}

\begin{Def}{Vettori linearmente indipendenti}
  Dati $l$ vettori $\vec{v_1},\ldots,\vec{v_l}$ di $V$ su $\mathbb{K}$, si dicono
  linearmente indipendenti se l'unica loro combinazioni lineare uguale a $\vec{o}$ è
  quella che ha coefficienti tutti nulli.
\end{Def}

\begin{SubDef}{Insieme libero}
  L'insieme di vettori linearmente indipendenti è un insieme libero.
\end{SubDef}

\begin{Def}{Vettori linearmente dipendenti}
  Dati $l$ vettori $\vec{v_1},\ldots,\vec{v_l}$ di $V$ su $\mathbb{K}$, si dicono
  linearmente dipendenti se esiste almeno una combinazione lineare uguale a $\vec{o}$ a
  coefficienti non tutti nulli.
\end{Def}

\begin{Thm}{Dipendenza lineare e combinazioni lineari}
  Dati $l$ vettori $\vec{v_1},\ldots,\vec{v_l}$ di $V$ su $\mathbb{K}$ essi sono
  linearmente dipendenti se e solo se uno è combinazione lineare degli altri.
\end{Thm}

\begin{proof}
  Essendo un se e solo se, si devono dimostrare entrambe le implicazioni. Dimostrando
  $\Rightarrow$, si può dire per ipotesi che i vettori sono linearmente indipendenti, e
  quindi
  \begin{equation*}
    \exists x_1\vec{v_1}+\cdots+x_l\vec{v_l}=\vec{o}\qq{con} x_1\neq0
  \end{equation*}
  Isolando $\vec{v_1}$ si dimostra
  \begin{equation*}
    \vec{v_1}= - \frac{x_2}{x_1}\vec{v_1}-\cdots-\frac{x_l}{x_1}\vec{v_l}
  \end{equation*}
  L'altra implicazione ($\Leftarrow$) si dimostra anlogamente. Per ipotesi se
  \begin{equation*}
    \vec{v_i}=\lambda_1\vec{v_1}+\cdots+\lambda_{i-1}\vec{v_{i-1}}+
    \lambda_{i+1}\vec{v_{i+1}}+\cdots+\lambda_l\vec{v_l}
  \end{equation*}
  allora
  \begin{equation*}
    \vec{o} =
    \lambda_1\vec{v_1}+\cdots\lambda_{i-1}\vec{v_i-1}-\vec{v_i}+\lambda_{i+1}\vec{v_i+1}
    +\cdots+\lambda_l\vec{v_l}
  \end{equation*}
\end{proof}

\subsection{Base di uno spazio vettoriale}%
\label{sub:base_di_uno_spazio_vettoriale}

\begin{Def}{Base}
  Un insieme finito e ordinato di $V$ denotato con
  $\mathscr{B}(\vec{v_1},\ldots,\vec{v_n})$ è detto base di $V$ se è insieme libero e un
  sistema di generatori.
\end{Def}

\begin{SubDef}{Basi canoniche o standard}
  In $\mathbb{R}^n$,
  \begin{equation*}
    \mathscr{B}\bigl((1,0,\ldots,0),(0,1,0,\ldots,0),\ldots,(0,\ldots,0,1)\bigr)
  \end{equation*}
  è detto base canonica o standard.\\[\baselineskip]
  In $\mathbb{R}^{m,n}$ la base canonica o standard è
  \begin{equation*}
    \mathscr{B} \left(
      \begin{pmatrix}
        1 & 0 &\cdots\\
        0 & 0 & \cdots\\
        \vdots & \vdots & \cdots
      \end{pmatrix},\ldots,
      \begin{pmatrix}
        0 & \cdots & 0\\
        \vdots & 1 & \vdots\\
        0 & \cdots & 0
      \end{pmatrix}
    \right)
  \end{equation*}
  Ovvero sono le matrici che al posto di indici $_{ij}$ è $1$, ovunque è
  $0$.\\[\baselineskip]
  Su $\mathbb{R}_n[x]$ (ovvero l'insieem dei polinomi reali in $x$ con grado minore o
  uguale a $n$) una base canonica o standard è $(1,x,x^2,\ldots,x^n)$.
\end{SubDef}

\begin{Thm}{Caratterizzazione di uno spazio vettoriale}
  Sia $\mathscr{B}=(\vec{v_1},\ldots,\vec{v_n})$ una base di $V$, allora ogni $x\in V$
  si scrive in un modo unico come combinazione lineare dei vettori $\vec{v_1},\ldots,
  \vec{v_n}$ come $\vec{v}=x_1\vec{v_1}+\cdots+x_n\vec{v_n}$ e $(x_1,\ldots,x_n)\in
  \mathbb{K}^n$.\\
  Viceversa se si hanno $n$ vettori $\{\vec{v_1},\ldots,\vec{v_n}\}$ ed essi sono
  l'insieme di tutti i vettri in $V$ tali che $\forall \vec{x}\in V$ si ha
  $\vec{x}=x_1\vec{v_1}+\cdots+x_n\vec{v_n}$, allora $(\vec{v_1},\ldots,\vec{v_n})$ è
  una base di $V$.
\end{Thm}

\begin{proof}
  Essendo diviso in due punti, dimostriamo il primo. Se $\mathscr{B}$ è una base, allora
  $\{\vec{v_1},\ldots,\vec{v_n}\}$ è un sistema di generatori. Allora
  $\vec{x}=x_1\vec{v_1}+\cdots+x_n\vec{v_n}$. Se la decomposizione non è unica, allora
  $\vec{x}=x'_1\vec{v_1}+\cdots+x'_n\vec{v_n}$ con $x'_1\neq0$ si può riscrivere come
  $(x'_1-x_1)\vec{v_1}+\cdots+(x'_n-x_n)\vec{x_n}=\vec{o}$ ma questo è un assurdo in
  quanto $x'_1-x_1\neq0$ contro l'ipotesi che $\vec{v_1},\ldots,\vec{v_n}$ siano
  linearmente indipendenti.\\
  Per il secondo punto, sappiamo che $\{\vec{v_1},\ldots,\vec{v_n}\}$ è un sistema di
  generatori. Se si prende $\lambda_1\vec{v_1}+\cdots+\lambda_n\vec{v_n}=\vec{o}$, lo si
  scrive in odo unico come combinazione lineare di $\vec{v_1},\ldots,\vec{v_n}$ per
  ipotesi. Quindi $\lambda_1=\cdots=\lambda_n=0$.
\end{proof}

\begin{Def}{Componenti di un vettore}
  Sia $V$ uno spazio vettoriale su $\mathbb{K}$. Sia $\mathscr{B}=(\vec{v_1},\ldots,
  \vec{v_n})$ una base fissata di $V$. Allora $\forall \vec{x}\in V$ si ha
  $\vec{x}=x_1\vec{v_1}+\cdots+x_n\vec{v_n}$ con $x_i\in\mathbb{K}$ e $(x_1,\ldots,x_n)$
  sono dette componenti di $\vec{x}$ rispetto alla base $\mathscr{B}$. In simboli si
  scrive ${(\vec{x})}_\mathscr{B}=(x_1,\ldots,x_n)$.
\end{Def}

\begin{Thm}{Esistenza della base}
  Sia $V$ uno spazio vettoriale su $\mathbb{K}$ finitamente generato e sia
  $G=\{\vec{w_1},\ldots,\vec{w_l}\}$ un sistema di generatori di $V$. Allora $G$
  contiene almeno una base.
\end{Thm}

\begin{proof}
  Anhe denominato metodo degli scarti successivi, questa dimostrazione permette di
  trovare una base per uno spazio vettoriale.\\
  Si tolga il vettore nullo, se presente. Allora si può supporre che ogni vettore non
  sia nullo. \textbf{Primo passo}: Si consideri l'insieme libero $I_1=\{\vec{w_1}\}$. Se
  ogni vettore $\vec{w_i}$ con $i=1,\ldots,l$ è linearmente dipendente con $\vec{w_1}$
  allora $\vec{w_1}$ è una base di $V$ perché $\mathscr{L}(\vec{w_1})=V$ e $\{\vec{w_1}\}$
  è libero. Se invece $\mathscr{L}(\vec{w_1})\neq V$, si considera il primo vettore di
  $V$ che sia linearmente indipendente con $\vec{w_1}$. Ad esempio
  $\vec{w_2}\notin\mathscr{L}(\vec{w_1})$. \textbf{Secondo passo}: Si consideri
  l'insieme libero $I_2=\{\vec{v_1},\vec{w_2}\}$. Si hanno due possibilità, ogni
  $\vec{w_i}$ con $i\neq1,2$ è combinazione lineare di $\vec{w_1},\vec{w_2}$ e quindi
  $\{\vec{w_1},\vec{w_2}\}$ è una base di $V$ in quanto
  $\mathscr{L}(\vec{w_1},\vec{w_2})=V$. In caso contrario, esiste almeno un $\vec{w_i}$
  con $i\neq1,2$ che è linearmente indipendente con $\vec{w_1},\vec{w_2}$. \textbf{Terzo
  passo}: Si consideri l'insieme libero $I_3=\{\vec{w_1},\vec{w_2},\vec{w_3}\}$. Si
  procede come nel secondo passo.\\
  Il procedimento termina dopo un numero finito di passi, al più $l$. Da $G$ si
  costruisce un insieme libero di generatori di $V$ e quindi una base di $V$.
\end{proof}

\begin{Thm}{Lemma di Steintz}
  Sia $\mathscr{B}=(\vec{v_1},\ldots,\vec{v_n})$ una base di $V$ su $\mathbb{K}$ e sia
  $I=\{\vec{u_1},\ldots,\vec{u_p}\}$ un insieme libero.  Allora $p\leq n$.
\end{Thm}

\begin{proof}
  Siano ${(\vec{u_1})}_\mathscr{B}=(\lambda_1,\ldots,\lambda_n)$ i componenti. $I$ è
  libero, quindi $\vec{u_1}\neq\vec{o}$. Ciò cimplica che almeno una delle componenti
  $\lambda_i\neq0$. Supponiamo senza perdita di generalità che sia $\lambda_1\neq0$.
  Allora
  \begin{equation}\label{eq:spazio_steintz_dim}
    \vec{u_1}=\lambda_1\vec{v_1}+\cdots+\lambda_n\vec{v_n}\tag{$\star$}
  \end{equation}
  Isolando $\vec{v_1}$ otteniamo
  \begin{equation*}
    \vec{v_1} =
    \frac{1}{\lambda_1}\vec{u_1}-\frac{\lambda_2}{\lambda_1}\vec{v_2}-\cdots-
    \frac{\lambda_n}{\lambda_1}\vec{v_n}
  \end{equation*}
  Quindi $\vec{v_1}\in\mathscr{L}(\vec{u_1},\vec{v_2},\ldots,\vec{v_n})$. Si nota che
  $\{\vec{u_1},\vec{v_2},\ldots,\vec{v_n}\}$ è ancora una base di $V$ in quanto è un
  sistema di generatori linearmente indipendenti.\\
  Per~\eqref{eq:spazio_steintz_dim}, sappiamo $\forall x\in V$ si ha
  $\vec{x}=x_1\vec{v_1}+\cdots+x_n\vec{v_n}$ dato che $\mathscr{B}$ è una base di $V$.
  Sostituendo si ottiene
  \begin{equation*}
    \vec{x}=x_1 \left(
    \frac{1}{\lambda_1}\vec{v_1}-\frac{\lambda_2}{\lambda1}\vec{v_2}-\cdots-
  \frac{\lambda_n}{\lambda_1}\vec{v_n}\right)+\cdots+x_n\vec{v_n}
  \end{equation*}
  Quindi $x\in\mathscr{L}(\vec{u_1},\vec{v_2},\ldots,\vec{v_n})$. Allora sicuramente
  $\{\vec{u_1},\vec{v_2},\ldots,\vec{v_n}\}$ è un sistema di generatori di $V$. È anche
  libero in quanto è formato da $\{\vec{v_2}\,\ldots,\vec{v_n}\}$ che è libero e
  $\vec{u_1}\notin\mathscr{L}(\vec{v_2},\ldots,\vec{v_n})$. Definiamo
  $\mathscr{B}_1(\vec{u_1},\vec{v_2},\ldots,\vec{v_n})$.\\
  Iterando il procedimento considerando $\vec{u_2}\in I$ si scrive $\vec{u_2}$ come
  combinazione lineare di vettori della base $\mathscr{B}_1$.
  \begin{equation*}
    \vec{u_2}=\gamma_1\vec{u_1}+\gamma_2\vec{v_2}+\cdots+\gamma_n\vec{v_n}
  \end{equation*}
  Poiché $\vec{u_2}\neq\vec{o}$, almeno uno dei coefficienti non è nullo. Poiché
  $\{\vec{u_1},\vec{u_2}\}$ è libero per costruzione, non si può avere $\gamma_1\neq0$ e
  $\gamma_2=\cdots=\gamma_n=0$. Si può supporre che $\gamma_2\neq0$. Possiamo scrivere
  $\vec{v_2}$ come combinazione lineare di
  $\vec{u_1},\vec{u_2},\vec{v_3},\ldots,\vec{v_n}$ e si prova che
  $\mathscr{B}_2(\vec{u_1},\vec{u_2},\vec{v_3},\ldots,\vec{v_n})$ è una base di $V$. Si
  procede poi con $\vec{v_3}$.\\
  Il procedimento termina se o si sono estrtti tutti i vettori di $I$ e sono stati
  inseriti tutti i vettori di $I$ nella base (ovvero $p\leq n$) oppure si sono estratti
  i vettori di $\mathscr{B}$ e rimangono ancora vettori di $I$ (ovvero
  $\mathscr{B}\subset I$) ma ciò è un assurdo perché $\mathscr{B}$ è una base e se fosse
  vero, gli elementi di $I$ in più sarebbero linearmente indipendenti ma ciò è
  impossibile.
\end{proof}

\begin{SubThm}{Numero di elementi di una base}
  Tutte le basi di uno spazio vettoriale finitamente gnerato hanno lo stesso numero di
  vettori.
\end{SubThm}

\begin{proof}
  Per assurdo $\mathscr{B}(\vec{v_1},\ldots,\vec{v_n})$ e
  $\mathscr{B}'(\vec{w_1},\ldots,\vec{w_l})$. Allora se consideriamo $\mathscr{B}$ base,
  $\mathscr{B}'$ è un insieme libero e quindi $n\geq l$. Se invece consideriamo
  $\mathscr{B}'$ base e $\mathscr{B}$ un insieme libero, si ha $n\leq l$ da cui si
  deduce che $n=l$.
\end{proof}
